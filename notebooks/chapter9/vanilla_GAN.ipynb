{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNnCEE/xEqO0nSrbFiJkq8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shekharkhandelwal1983/DLforDataArchitects/blob/main/notebooks/chapter9/vanilla_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow implementation"
      ],
      "metadata": {
        "id": "FIeBr15o6_3H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eUy6w_nCzM6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5aa920-7930-4241-88c7-34897758aaa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7f9423675240>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 103, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the training data\n",
        "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "# Reshape the training data to (batch_size, 28, 28, 1)\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJaxuF7BzRFm",
        "outputId": "af65c87c-3eb8-4a94-99e9-14ed14de2dfa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(z, reuse=False):\n",
        "  with tf.variable_scope(\"generator\", reuse=reuse):\n",
        "    # Define the model layers\n",
        "    x = tf.layers.dense(z, units=7*7*128)\n",
        "    x = tf.nn.leaky_relu(x)\n",
        "    x = tf.reshape(x, shape=(-1, 7, 7, 128))\n",
        "    x = tf.layers.conv2d_transpose(x, filters=64, kernel_size=5, strides=2, padding=\"same\")\n",
        "    x = tf.nn.leaky_relu(x)\n",
        "    x = tf.layers.conv2d_transpose(x, filters=1, kernel_size=5, strides=2, padding=\"same\")\n",
        "    x = tf.nn.tanh(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "R5U3r2eJzWci"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator(x, reuse=False):\n",
        "  with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
        "    # Define the model layers\n",
        "    x = tf.layers.conv2d(x, filters=64, kernel_size=5, strides=2, padding=\"same\")\n",
        "    x = tf.nn.leaky_relu(x)\n",
        "    x = tf.layers.conv2d(x, filters=128, kernel_size=5, strides=2, padding=\"same\")\n",
        "    x = tf.nn.leaky_relu(x)\n",
        "    x = tf.reshape(x, shape=(-1, 7*7*128))\n",
        "    x = tf.layers.dense(x, units=1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4K5cDKoKzZ9w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you see this error in the placeholder code - AttributeError: module 'tensorflow' has no attribute 'placeholder'\n",
        "\n",
        "The error you are encountering (AttributeError: module 'tensorflow' has no attribute 'placeholder') suggests that you are using TensorFlow 2.x, which does not have the tf.placeholder function as it was a part of TensorFlow 1.x.\n",
        "\n",
        "TensorFlow 2.x encourages the use of an eager execution model and does not use placeholders and sessions like TensorFlow 1.x. Instead, you should use other mechanisms such as tf.data.Dataset for feeding data to your models.\n",
        "\n",
        "If you absolutely need to use the TensorFlow 1.x syntax, you can enable the compatibility mode in TensorFlow 2.x by using the following code:"
      ],
      "metadata": {
        "id": "EsHUMQTd0KL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VA-SjCKz-ds",
        "outputId": "eb4c71de-672f-42f0-f8be-8b9537b1d51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = tf.placeholder(tf.float32, shape=(None, 100))"
      ],
      "metadata": {
        "id": "bSRL0XMnzcRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))"
      ],
      "metadata": {
        "id": "s8C70A65zeS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator model\n",
        "G = generator(z)\n",
        "\n",
        "# Define the discriminator model for real images\n",
        "D_real = discriminator(x)\n",
        "\n",
        "# Define the discriminator model for synthetic images\n",
        "D_fake = discriminator(G, reuse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_LBa1df0C8_",
        "outputId": "0228fa6c-8c61-4b2f-b426-aa15a4157fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-304de63e1587>:4: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  x = tf.layers.dense(z, units=7*7*128)\n",
            "<ipython-input-3-304de63e1587>:7: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "  x = tf.layers.conv2d_transpose(x, filters=64, kernel_size=5, strides=2, padding=\"same\")\n",
            "<ipython-input-3-304de63e1587>:9: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "  x = tf.layers.conv2d_transpose(x, filters=1, kernel_size=5, strides=2, padding=\"same\")\n",
            "<ipython-input-4-e5ec21030c2c>:4: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  x = tf.layers.conv2d(x, filters=64, kernel_size=5, strides=2, padding=\"same\")\n",
            "<ipython-input-4-e5ec21030c2c>:6: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  x = tf.layers.conv2d(x, filters=128, kernel_size=5, strides=2, padding=\"same\")\n",
            "<ipython-input-4-e5ec21030c2c>:9: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  x = tf.layers.dense(x, units=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator loss\n",
        "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake, labels=tf.ones_like(D_fake)))"
      ],
      "metadata": {
        "id": "E5QhXQv80Y7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real, labels=tf.ones_like(D_real)))"
      ],
      "metadata": {
        "id": "yHYYml3U0bu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake, labels=tf.zeros_like(D_fake)))"
      ],
      "metadata": {
        "id": "tfKHnVYA0d9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_loss = d_loss_real + d_loss_fake"
      ],
      "metadata": {
        "id": "zJ1Hveq-0f5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizers\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Get the trainable variables for the generator and discriminator\n",
        "t_vars = tf.trainable_variables()\n",
        "g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n",
        "d_vars = [var for var in t_vars if var.name.startswith(\"discriminator\")]\n",
        "\n",
        "# Define the optimizers\n",
        "g_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
        "d_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)"
      ],
      "metadata": {
        "id": "1C9hfgPF0h41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1VxH9ngw1tp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3jLVvtc1tsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch implementation"
      ],
      "metadata": {
        "id": "VG2WaiiX7Eui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "ap0KhH7G1tua"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jea_JutV1uMo",
        "outputId": "f1a640c7-cf4f-411d-8910-f738ecd4eca9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 119630629.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 44177860.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 44640254.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 18936907.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(100, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 28*28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1, 1, 28, 28)\n",
        "\n",
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(28*28, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input.view(-1, 28*28))\n"
      ],
      "metadata": {
        "id": "q9Ry8WKF1wF7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Generator and Discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimizers\n",
        "lr = 0.0002\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "id": "Iiqry4St1zEB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "latent_vector_size = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        # Labels\n",
        "        real_labels = torch.ones(batch_size, 1)\n",
        "        fake_labels = torch.zeros(batch_size, 1)\n",
        "\n",
        "        # Train Discriminator\n",
        "        outputs = discriminator(images)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        real_score = outputs\n",
        "\n",
        "        z = torch.randn(batch_size, latent_vector_size)\n",
        "        fake_images = generator(z)\n",
        "        outputs = discriminator(fake_images.detach())\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        fake_score = outputs\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        optimizer_D.zero_grad()\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        z = torch.randn(batch_size, latent_vector_size)\n",
        "        fake_images = generator(z)\n",
        "        outputs = discriminator(fake_images)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.6f}, g_loss: {g_loss.item():.6f}, '\n",
        "          f'D(x): {real_score.mean().item():.6f}, D(G(z)): {fake_score.mean().item():.6f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YCOgYJg101A",
        "outputId": "dbb2b43c-137d-4e41-d00f-c90b810950ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], d_loss: 0.034503, g_loss: 5.597266, D(x): 0.981908, D(G(z)): 0.015206\n",
            "Epoch [2/30], d_loss: 2.263186, g_loss: 7.456955, D(x): 0.464009, D(G(z)): 0.092408\n",
            "Epoch [3/30], d_loss: 0.054215, g_loss: 6.670505, D(x): 0.973806, D(G(z)): 0.016396\n",
            "Epoch [4/30], d_loss: 0.299189, g_loss: 3.030844, D(x): 0.898756, D(G(z)): 0.089467\n",
            "Epoch [5/30], d_loss: 0.638837, g_loss: 3.418792, D(x): 0.890473, D(G(z)): 0.152273\n",
            "Epoch [6/30], d_loss: 1.520650, g_loss: 3.675486, D(x): 0.804356, D(G(z)): 0.091025\n",
            "Epoch [7/30], d_loss: 0.056091, g_loss: 5.273903, D(x): 0.981668, D(G(z)): 0.032277\n",
            "Epoch [8/30], d_loss: 0.062765, g_loss: 6.902851, D(x): 0.968569, D(G(z)): 0.014131\n",
            "Epoch [9/30], d_loss: 0.233605, g_loss: 4.602305, D(x): 0.963033, D(G(z)): 0.146686\n",
            "Epoch [10/30], d_loss: 0.167798, g_loss: 4.037113, D(x): 0.953258, D(G(z)): 0.046168\n",
            "Epoch [11/30], d_loss: 0.169272, g_loss: 8.138865, D(x): 0.976938, D(G(z)): 0.108432\n",
            "Epoch [12/30], d_loss: 0.379817, g_loss: 6.563625, D(x): 0.862630, D(G(z)): 0.048761\n",
            "Epoch [13/30], d_loss: 0.394333, g_loss: 3.678597, D(x): 0.882327, D(G(z)): 0.022845\n",
            "Epoch [14/30], d_loss: 0.432354, g_loss: 2.951236, D(x): 0.904966, D(G(z)): 0.172249\n",
            "Epoch [15/30], d_loss: 0.450021, g_loss: 5.954128, D(x): 0.928717, D(G(z)): 0.039118\n",
            "Epoch [16/30], d_loss: 0.485036, g_loss: 4.902407, D(x): 0.897131, D(G(z)): 0.115474\n",
            "Epoch [17/30], d_loss: 0.515086, g_loss: 3.932154, D(x): 0.785141, D(G(z)): 0.095748\n",
            "Epoch [18/30], d_loss: 0.775779, g_loss: 5.022182, D(x): 0.778029, D(G(z)): 0.044034\n",
            "Epoch [19/30], d_loss: 0.267092, g_loss: 3.475733, D(x): 0.898639, D(G(z)): 0.113675\n",
            "Epoch [20/30], d_loss: 0.492119, g_loss: 2.390257, D(x): 0.841673, D(G(z)): 0.076158\n",
            "Epoch [21/30], d_loss: 0.526111, g_loss: 2.898717, D(x): 0.887969, D(G(z)): 0.214987\n",
            "Epoch [22/30], d_loss: 0.422580, g_loss: 3.601164, D(x): 0.915552, D(G(z)): 0.171813\n",
            "Epoch [23/30], d_loss: 0.330665, g_loss: 2.849438, D(x): 0.855336, D(G(z)): 0.105068\n",
            "Epoch [24/30], d_loss: 0.444560, g_loss: 3.321378, D(x): 0.885607, D(G(z)): 0.114027\n",
            "Epoch [25/30], d_loss: 0.501110, g_loss: 3.022962, D(x): 0.806900, D(G(z)): 0.095951\n",
            "Epoch [26/30], d_loss: 0.620401, g_loss: 3.614527, D(x): 0.753634, D(G(z)): 0.074130\n",
            "Epoch [27/30], d_loss: 0.398090, g_loss: 3.066267, D(x): 0.830674, D(G(z)): 0.088797\n",
            "Epoch [28/30], d_loss: 0.493753, g_loss: 2.118431, D(x): 0.839439, D(G(z)): 0.159639\n",
            "Epoch [29/30], d_loss: 0.414022, g_loss: 2.069277, D(x): 0.856553, D(G(z)): 0.122476\n",
            "Epoch [30/30], d_loss: 0.482462, g_loss: 3.105323, D(x): 0.933973, D(G(z)): 0.231428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.randn(1, latent_vector_size)\n",
        "sample_images = generator(z).detach().numpy().reshape(-1, 28, 28)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "for i in range(1):\n",
        "    plt.subplot(1, 1, i+1)\n",
        "    plt.imshow(sample_images[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "1dSrD7AU12n9",
        "outputId": "2ee6f516-78da-42f2-f9e2-1ec277f739ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAHiCAYAAADf3nSgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJaklEQVR4nO3dsXEVSRRAURrGAIMqsCgiUAzEQTpkATGQCjkQAIUnCo/ii14DZ6vWoFej4X59nWPPDM/4M1fPoceccz4CAP66x/UAAPBQiTAAREQYACIiDAAREQaAiAgDQESEASAiwgAQEWEAiGyrF44xjpwDAC7Kyn9IaRMGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMAJGtHgCA306n0+5nbJvP+n1iEwaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAImPOOZcuHOPoWQDgYqzk1SYMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiWz0AwMrh538yxth1/8uXL3fPcH19vfsZPCw2YQCIiDAAREQYACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgMubiQZ57z+oELtf379933b9t+482//nz56773717t3uG9+/f734Gl2MlrzZhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQESEASAiwgAQ2X+SNvDgPX/+vB7h0bNnz3bd//nz5zuaBNbZhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAyJhzzqULxzh6FuCeWvyMHOrr16+77n/9+vUdTQK/rbwXNmEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABAZc/E07jHG0bMAgcVPwNnzjeLcrLxbNmEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAENnqAYB9Pn36VI+w27b5FPEw2YQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgMiYc86lC8c4ehbgFhZf4bPm+8IlWnk3bcIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQESEASCy1QPAQ3Z1dVWPcCdevXpVjwD3kk0YACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiMOedcunCMo2eBB2fx9Tt7vg/wXyvvt00YACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABEtnoAuM++fPlSj7DbysHjwDFswgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANAZMzFw0THGEfPAvfOJZzF692GY6x8H2zCABARYQCIiDAAREQYACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgstUDAPu8efOmHgG4JZswAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABAZc865dOEYR88Cf9XiT//sPX36dNf9P378uKNJgH9b+cbYhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQGTMxZPNxxhHzwJ/1eJP/+x5N+E8rXxjbMIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQGSrB4Dbevv2bT0CwC42YQCIiDAAREQYACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBlzzrl04RhHzwL/y+JP96x5r+ByrXyjbMIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQGSrB4DbOp1Ou+7fNj9/oGUTBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEaeak7i6utr9jG3z8wXuN5swAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABAZc865dOEYR88C/8vpdNp1/5MnT3bPsPdM45ubm90zAHfvxYsXu59xfX39x2tswgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBILLvRHIIffz4cdf9Hz582D3Dzc3N7mdcgseP9/09/+vXrzuaBO7Gt2/f/sq/YxMGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACJjzjmXLhzj6FkA4GKs5NUmDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAiAgDQESEASAiwgAQEWEAiIgwAEREGAAiIgwAEREGgIgIA0BEhAEgIsIAEBFhAIiIMABERBgAIiIMABERBoCICANARIQBICLCABARYQCIiDAAREQYACIiDACRbfXCOeeRcwDAg2MTBoCICANARIQBICLCABARYQCIiDAAREQYACIiDAAREQaAyD891LTPWdoe4AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzRYy7XX16zv"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}